---
title: "Algorithm Implementations"
author: "Christian Pascual"
date: "3/9/2019"
output: html_document
---

```{r, message = FALSE}
library(tidyverse)
library(datasets)
library(knitr)
library(MASS)
```


<h1 id="toc">Table of Contents</h1>

## <a href="#mc">Monte Carlo</a>
  * <a href="#inv-cdf">Inverse CDF</a>
  * <a href="#acrej">Acceptance-Rejection</a>
  * <a href="#mc-int">Monte Carlo Integration</a>
  * <a href="#impt-samp">Importance Sampling</a>
  * <a href="#anti">Antithetic Approach</a>
  * <a href="#cont-var">Control Variates</a>
  
## <a href="#em">EM Algorithm</a>
  * <a href="#gauss-mix">Mixed Gaussian</a>
  * <a href="#zip">Zero Inflated Poisson</a>
  * <a href="#bulbs">Lightbulbs</a>
  * <a href="#fisher">Fisher's Genotype</a>
  * <a href="#abo">ABO Blood Type</a>
  * <a href="#kmeans">K-Means</a>
  
<h2 id="mc">Monte Carlo</h2>

<h3 id="inv-cdf">Inverse CDF</h2>

$X$ is a random variable with cdf $F(X)$ which has an inverse $F^{-1}(X)$. If you plug in a uniform random variable $U$, the resulting random variable will have the same density as $X$.

#### Examples

```{r}
# Generate a Laplace distribution
n = 1000
laplace.generator = tibble(
  uniform_vals = runif(n),
  laplace_vals = log(2 * uniform_vals) * (uniform_vals <= 0.5) -
    log(2 - 2 * uniform_vals) * (uniform_vals > 0.5),
  nums = seq(-10, 10, length = n),
  true_laplace = 0.5 * exp(-abs(nums)) 
)
```

<a href="#toc">Back to top</a>

<h3 id="acrej">Acceptance-Rejection</h2>

A method for generating a random number sequence in cases where the inverse CDF of the desired density does not have a closed form. You have a target pdf/cdf $F(.)$, so you should pick a $G(.)$ that is easy to sample from (ie can just generate from R or use inverse-CDF to generate). $G(.)$ should also have the same range as the target density.

The ratio $\frac{f(Y)}{Mg(Y)}$ is also a random variable that takes values from 0 to one. $M$ is chosen to be the supremum of $\frac{f(X)}{g(X)}$ in practice.

After generating a bunch of $y$ from the distribuion $g(Y)$ and a bunch of uniforms, you keep all the $y$ that satisfy the inequality $u \leq \frac{f(Y)}{Mg(Y)}$

#### Code
```{r}
# From lecture
accrej <- function(fdens, gdens, M, x)
  return(x[runif(length(x)) <= fdens(x) / (M * gdens(x))])
```

<a href="#toc">Back to top</a>

<h3 id="mc-int">Monte Carlo Integration</h2>

Sometimes you have integrals that you can't compute analytically. Since you have to compute it numerically, it would be good to use Monte Carlo integration.

$$\int^b_ag(x)dx = (b-a)\int^b_ag(x)\frac{1}{b-a}dx = (b-a)E(g(U) \approx(b-a)\frac{1}{n}\sum^n_{i=1}g(U_i)$$

<h3 id="impt-samp">Importance Sampling</h2>

You may also generalize the above to any distribution $X$:
$$\int^b_ag(x)dx = \int^b_a\frac{g(x)}{p(x)}p(x)dx = E(\frac{g(X_i)}{p(X_i)}) \approx \frac{1}{n}\sum\frac{g(X_i)}{p(X_i)}$$

Since a and b are the ends of the support of $p(X)$, it essentially acts as an expectation.

<a href="#toc">Back to top</a>

<h3 id="anti">Antithetic Approach</h2>

A variant of Monte Carlo intergration. Used to minimize the variance of the estimated numerical estimation of the integral.

$$\int^1_0g(x)dx = \int^1_0\frac{1}{2}[g(x) + g(1-x)]dx$$
The right hand side has a lower variance than the original Monte Carlo integration.

<a href="#toc">Back to top</a>

<h3 id="cont-var">Control Variates</h2>

Another variation of Monte Carlo Integration and another way to reduce variance of the estimated integral. In general, represented as:
$$\int g(x)f(x)dx = \int m(x)f(x)dx + \int(g(x) - m(x)) f(x)dx$$

This is approximated by:
$$\int m(x)f(x)dx + \int(g(x) - m(x)) f(x)dx = \int m(x)f(x)dx + \frac{1}{n}\sum(g(X_i) - m(X_i))$$

$m(x)$ is chosen such that the left integral can be solved for analytically. You want $g(X)$ and $m(X)$ to be very highly positively correlated (unlike negatively correlated in antithetic approach).

This approach can also take advantage of a weighting verion
$$\beta\int m(x)f(x)dx + \frac{1}{n}\sum(g(X_i) - \beta m(X_i))$$

where $\beta$ is the coefficient recieved from regressing $g(X)$ from $m(X)$

<a href="#toc">Back to top</a>

<h2 id="em">EM Algorithm</h2>  

### General Workflow:

1) What is the observed likelihood that you want to maximize?
2) What is the latent data that you have to model?
3) What is the complete likelihood incorporating the latent data?
4) What is the expression for the expectation?
5) Calculate your expected value of your latent in E-step
6) Calculate your new parameters based on this expectation
7) Iterate until convergence

<h3 id="gauss-mix">Mixed Gaussian</h3>

Your population is actually a mixture of two Gaussians, and you want to estimate the best $\mu_1, \sigma_1, \mu_2, \sigma_2$ to maximize the observed likelihood:

$$L_{obs}(x) = \prod^n_{i=1}(1 - p)f(x_i, \mu_1, \sigma_1) + p f(x_i, \mu_2, \sigma_2)$$
where each $f$ is just a normal density function.

Your latent variable is $Z \sim Bin(1,p)$ such that if $Z = 0$, $X_i$ comes from the first normal and the second if $Z = 1$.

Thus, the complete log-likelihood is:
$$l(X,Z,\theta)  = \sum^n_{i=1}[Z_ilog(p) + (1-Z_i)log(1-p) +Z_ilogf_2 + (1-Z_i)f_1]$$

#### E-step: given current parameters, what is the expectation?

Define $\delta^{(t)}_i = E(Z_i|x_i, \theta^{(t)})$ as the expected value of the complete log-likelihood. $\delta^{(t)}_i$ will then become our current guess for $Z_i$.

The expected value of $Z$ is the same as the expected value of a binomial. We can use Bayes' Theorem to calculate this estimate:

$$\delta^{(t)} = P(Z_i = 1|x_i, \theta^{(t)}) = \frac{p^{(t)}f_2}{p^{(t)}f_2^{(t)} +(1 - p^{(t)}f_1^{(t)})}$$

#### M-step: given the current estimate, what are the new parameters that maximize the complete log-likelihood?

The next set of parameters $\theta^{(t+1)}$ are those that maximize the complete log-likelihood, substituting $\delta^{(t)}_i$ for $Z_i$. (ie derive with respect to each of the parameters you need and set it to zero, solve for the parameter)

#### Code

```{r}
# E-step evaluating conditional means E(Z_i | X_i , pars)
delta <- function(X, pars){
  # X is the dataset, pars contains the current estimates for the parameters
  phi1 <- dnorm(X, mean = pars$mu1, sd = pars$sig1)
  phi2 <- dnorm(X, mean = pars$mu2, sd = pars$sig2)
  return(pars$p * phi2 / ((1 - pars$p) * phi1 + pars$p * phi2))
}

# M-step - updating the parameters
mles <- function(Z, X) {
  n <- length(X)
  phat <- sum(Z) / n
  mu1hat <- sum((1 - Z) * X) / (n - sum(Z))
  mu2hat <- sum(Z * X) / sum(Z)
  sigmahat1 <- sqrt(sum((1 - Z) * (X - mu1hat)^2 ) / (n - sum(Z)))
  sigmahat2 <- sqrt(sum(Z * (X - mu2hat)^2) / sum(Z))
  return(list(phat = phat, 
              mu1 = mu1hat, mu2 = mu2hat, 
              sig1 = sigmahat1, sig2 = sigmahat2))
}

# The actual iteration through the algorithm
# Added the convergence check 
EMmix <- function(X, start, nreps = 100, tol = 1e-5) {
  i = 0 # iteration start
  
  # Usually given numbers that let you recalculate Z
  Z = delta(X, start)
  
  old.params = start

  res = c(i, phat = old.params$phat, 
          mu1 = old.params$mu1, mu2 = old.params$mu2,
          sig1 = old.params$sig1, sig2 = old.params$sig2)
  
  diff.phat = diff.mu1 = diff.mu2 = diff.sig1 = diff.sig2 = Inf
  
  while (i < nreps && diff.phat > tol && 
         diff.mu1 > tol && diff.mu2 > tol &&
         diff.sig1 > tol && diff.sig2 > tol) {     
    
    i = i + 1 # increase the iteration
    new.params <- mles(Z, X) # Recalculate params with new delt
    
    
    # Convergence check
    diff.phat = abs(new.params$phat - old.params$phat)
    diff.mu1 = abs(new.params$mu1 - old.params$mu1)
    diff.mu2 = abs(new.params$mu2 - old.params$mu2)
    diff.sig1 = abs(new.params$sig1 - old.params$sig1)
    diff.sig2 = abs(new.params$sig2 - old.params$sig2)
    
    Z = delta(X, new.params) # Relculate the delta
    
    res <- rbind(res, 
                 c(i, phat = new.params$phat, 
                   mu1 = new.params$mu1, mu2 = new.params$mu2,
                   sig1 = new.params$sig1, sig2 = new.params$sig2))
    
    # set up for the next iteration
    old.params = new.params
  }
  return(res)
}

# confirmed it works
# data(faithful)
# res = EMmix(faithful$waiting, 
#             start = list(phat = 0.5, 
#                          mu1 = 50, mu2 = 80, 
#                          sig1 = 15, sig2 = 15))
```

<a href="#toc">Back to top</a>

<h3 id="zip">Zero-Inflated Poisson</h3>

You have too many zeros in your data to be correctly modelled as a Poisson distirbution. The latent variable must be some underlying process that produces "true zeros" (women who are just widows and bore no children) and pseudo-zeros (widows who... have dead children?).

The observed likelihood
$$pI[Y_i= 0]  + (1 - p)e^{-\lambda}\frac{\lambda^{Y_i}}{y_i!}$$

The latent variable is some Beroulli that describes your chance of being a true zero. Thus, there will be $z_i$ true zeros and $1-z_i$ pseudo-zeroes.

The complete likelihood:
$$\prod^n_{i=1}p^{z_i} \bigg( (1-p)e^{-\lambda}\frac{\lambda^{y_i}}{y_i!} \bigg)$$

and its log-likelihood counterpart:
$$\sum^n_{i=1} = z_ilog(p) + (1-z_i)[log(1-p) - \lambda + y_ilog(\lambda) - log(y_i!)]$$

where the $p$ is the probability that the subject comes from a true zero population.

#### E-step: 
$$z_i^{(t)} = E(z_i|Y_i) = P(z_i = 1|Y_i) = \frac{p^{(t)}}{p^{(t)} + (1 - p^{(t)})e^{-\lambda}}, Y_i = 0, (0 \, \text{otherwise})$$

#### M-step:
$$p^{(t+1)} = \frac{\sum z_i^{(t)}}{n}$$

$$\lambda^{(t+1)} = \frac{\sum Y_i(1 - z_i^{(t)})}{\sum z_i^{(t)}}$$

#### Code:
```{r}
Y <- c(rep(0,3062), rep(1,587), rep(2,284), 
       rep(3,103), rep(4,33), rep(5,4), rep(6,2))
n <- length(Y)

Q = function(Y, params){
  mid <- NULL
  for (ii in 1:n) {
    if (Y[[ii]] == 0) {
      mid[[ii]] = params$phat / (params$phat + (1 - params$phat) * exp(-params$lambda))
    } else { 
      mid[[ii]] = 0
    }
  }
  return(mid)
}

mles <- function(Y, Z) {
  phat <- sum(Z)/n
  lambda <- sum(Y * (1 - Z)) / (n - sum(Z))
  return(list(phat = phat, lambda = lambda))
}

EMmix <- function(Y, start, nreps = 100, tol = 1e-5) {
  i = 0
  Z = Q(Y, start)
  old.params = start
  res = c(iter = i, phat = start$phat, lambda = start$lambda)
  
  diff.phat = diff.lambda = Inf
  
  while (i < nreps && diff.phat > tol && diff.lambda > tol) {
    i = i + 1
    new.params = mles(Y, Z)
    
    diff.phat = abs(old.params$phat - new.params$phat)
    diff.lambda = abs(old.params$lambda - new.params$lambda)
    
    Z = Q(Y, new.params)
    res = rbind(res, 
                c(iter = i, phat = new.params$phat, lambda = new.params$lambda))
    old.params = new.params
    }
  return(res)
  }

# confirmed works
# res = EMmix(Y, start = list(phat = 0.2, lambda = 5))
```

<a href="#toc">Back to top</a>

<h3 id="bulbs">Lifetime and lightbulbs</h3>

For experiment one: you observe $X_1, \, ... \, , X_m$ iid sample times until light bulb death
For experiment two: you check if $m$ light bulbs at time $t$ and check if they're on. You observe $E_1, ..., E_n$ indicators $E_i = 1$ if on, $E_i = 0$ if off.

The life expectancy of any light bulb is modeled as an expoential distribution.

Since the $X_i$ are independent of the $Y_i$, the expectation looks like:
$$E[Y_i|X_i, E_i, \theta^t] = E[Y_i|E_i, \theta^t]$$

When the observed $E_i  =1$, the life expectancy is as follows due to the memoryless property of the exponential distribution:
$$E(Y_i|E_i = 1, \theta^t) =  t + \theta$$

When the observed $E_i  = 0$, the life expectancy is as follows due to the law of total expectation $E(X) = E(E(X|Y))$.

$$E(Y) = E(E(Y|E)) = E(Y|E = 0, \theta)P(E = 0, \theta) + E(Y|E = 1, \theta)P(E = 1, \theta)$$

$$\theta = E(Y|E = 0, \theta)(1 - e^{-t/\theta})+ (t + \theta)e^{-t/\theta}$$
Rearranging, we get:
$$E(Y|E = 0, \theta) = \theta - \frac{te^{-t/\theta}}{1 - e^{-t/\theta}}$$

Thus, for either case we can estimate the mean life time of each lifebulb using the latent variable


Then, the complete log-likelihood is:
$$l(\theta; X, Y) = -m(log(\theta) + \frac{\bar{X}}{\theta}) - \sum^n_{i=1}(log(\theta) + \frac{Y_i}{\theta})$$

and then we can estimate $\theta$ by:
$$\hat{\theta} = \frac{\sum X_i + \sum Y_i}{m+n}$$

We can interpret this as the mean minus the amount of time scaled. If the light isn't out, then due to the memoryless property we would just have the time plus the mean time added.

```{r}
delta = function(E, params) {  
  Ey0 = params$theta - params$t * exp(-params$t/params$theta) / (1 - exp(-params$t/params$theta))
  Ey1 = params$t + params$theta
  return((E == 0) * Ey0 + (E == 1) * Ey1)
}

mles <- function(delta, X, E) {
  t = 8
  m = length(X)
  n = length(E)
  thetahat = 1/(m + n) * (sum(X) + sum(delta))
  return(list(theta = thetahat, t = t))
}

Emix <- function(X, E, start, nreps = 10, tol = 1e-5) {
  i = 0
  old.params = start
  Z = delta(E, start)
  
  res = c(iter = 0, theta = old.params$theta)
  
  diff.theta = Inf
  
  while (i < nreps & diff.theta > tol) {
    i = i + 1
    new.params = mles(Z, X, E)
    Z = delta(E, new.params)
    diff.theta = abs(new.params$theta - old.params$theta)
    res = rbind(res, 
                c(iter = i, theta = new.params$theta))
    old.params = new.params
    }
  return(res)
}

# confirmed works
# n = 20
# m = 20
# X = c(4.0, 12.8, 2.9, 27.2, 2.9, 3.1, 11.2, 9.0, 8.1, 9.8,
#       13.7, 8.3, 1.2, 0.9, 8.0, 18.8, 2.6, 22.6, 1.7, 4.0)
# E = c(1, 0, 0, 0, 0, 1, 1, 1, 1, 1,
#        1, 1, 1, 1, 0, 0, 1, 0, 1, 0)
# res = Emix(X, E, start = list(theta = 1, t = 8), nreps = 50)
```

<a href="#toc">Back to top</a>

<h3 id="fisher">Fisher's Genotype</h3>

You have phenotype data of people and want to estimate allele frequencies. The loci are linked, so we get an observed likelihood for the phenotype data $Y$ for $n$ individuals:
$$Y \sim Multi(n, \frac{2+\psi}{4}, \frac{1-\psi}{4}, \frac{1-\psi}{4}, \frac{\psi}{4})$$

Since this is a multinomial distribution, we also know that the derivative of the log-likelihood with respect to $\psi$ is:
$$\frac{\delta l}{\delta\psi} = \frac{y_1}{2 + \psi} + \frac{y_2 + y_3}{1 - \psi} + \frac{4}{\psi}$$
But we cannot use Newton-Raphson because of that first probability cell. Since it's the sum of two numbers, let's say that $y_1$ can be split up into two independent, separate categories. Under the constraint $y_1 = y_{11} + y_{12}$, we can write a "complete" likelihood, which is another multinomial with 5 types:

$$Y_c = Multinomial(n, 0.5, \frac{\psi}{4}, \frac{1-\psi}{4}, \frac{1-\psi}{4}, \frac{\psi}{4})$$
Which means that the resulting complete log-likelihood is (removing terms without $\psi$):
$$l_c = (y_{12} + y_4)log(\psi) + (y_2 + y_3)log(1-\psi)$$

We also found that $y_{11} \sim Bin(y_1, \frac{0.5}{0.5 + \psi/4})$ and $y_{12} \sim Bin(n, \psi/4)$. So our E-step is:
$$E(y_{11}) = \frac{0.5y_1}{0.5 + \psi/4}$$

So, solving for $\psi$ with MLE and the linear equation that follows, we get the equation for the next $\psi^t$ in the M-step:
$$\psi^{(t)} = \frac{y_{12}^{(t)} + y_4}{y_{12}^{(t)} + y_2 + y_3 + y_4} = \frac{y_{12}^{(t)} + y_4}{n - y_{11}^{(t)} }$$

By extension:
$$y_{12}^{(t)} = E(y_{12}| y, \psi^{(t)}) = y_1 -  \frac{0.5y_1}{0.5 + \psi/4}$$

```{r}
E.step = function(Y, params) {
  # y = y1
  Ey11 = (0.5 * Y[1]) / (0.5 + params/4)
  Ey12 = Y[1] - Ey11
  return(list(y11 = Ey11, y12 = Ey12))
}

M.step = function(Y, E) {
  # Y - an array of the y counts
  # E - the expectation from the E-step
  psi = (E$y12 + Y[4]) / (E$y12 + Y[2] + Y[3] + Y[4])
  return(psi)
}

EM.mix = function(Y, start, nreps = 100, tol = 1e-5) {
  i = 0
  old.params = start
  E = E.step(Y, start)
  diff.psi = Inf
  res = c(iter = 0, psi = old.params)
  while (i < nreps && diff.psi > tol) {
    i = i + 1
    new.params = M.step(Y, E)
    diff.psi = abs(old.params - new.params)
    E = E.step(Y, new.params)
    
    res = rbind(res, c(iter = i, psi = new.params))
    old.params = new.params
  }
  return(res)
}

Y = c(125, 18, 20, 34)
res = EM.mix(Y, start = 0.5)
```


<a href="#toc">Back to top</a>

<h3 id="abo">ABO Blood Type</h3>

The complete likelihood of the number of individuals is:
$$
\begin{aligned}
l(n, p) = &N_{AA}log(p_A^2) + N_{AO}log(2p_Ap_O) + N_{BB}log(p_B^2) + N_{BO}log(2p_Bp_O) \\  &+ N_{AB}log(2p_Ap_B) + N_Olog(p_O^2) +log(\frac{n!}{N_{AA}N_{AB}N_{BB}N_{BO}N_{AB}N_{OO}})
\end{aligned}
$$

Using this equation as $Q(p, \lambda|p^{(k)})$ and the Lagrange multiplier, we want to maximize:
$$Q_L(p, \lambda|p^{(k)}) = Q(p|p^{(k)}) + \lambda(p_A + p_B + p_O - 1)$$

Solving for each parameter in the maximization step, we get:
$$p_A^{k+1} = \frac{2N^{(k)}_{AA} + N^{(k)}_{AO} + N^{(k)}_{AB}}{2n}$$
$$p_B^{k+1} = \frac{2N^{(k)}_{BB} + N^{(k)}_{BO} + N^{(k)}_{AB}}{2n}$$
$$p_O^{k+1} = \frac{2N^{(k)}_{OO} + N^{(k)}_{AO} + N^{(k)}_{BO}}{2n}$$

```{r abo-em-algo }
# E-step: calculating conditional means
e.calc = function(X, params) {
  # initial check for data
  if ("Na" %in% names(X) && "Nb" %in% names(X) ) {
    Na = X$Na
    Nb = X$Nb
  } else {
    Na = X$Naa + X$Nao
    Nb = X$Nbb + X$Nbo
  }
 
  return(list(
    Naa = Na * params$pa^2 / (params$pa^2 + 2 * params$pa * params$po),
    Nao = Na * 2 * params$pa * params$po / (params$pa^2 + 2 * params$pa * params$po),
    Nbb = Nb * params$pb^2 / (params$pb^2 + 2 * params$pb * params$po),
    Nbo = Nb * 2 * params$pb * params$po / (params$pb^2 + 2 * params$pb * params$po),
    Nab = X$Nab,
    Noo = X$Noo
  ))
}

# M-step: updating parameters
m.calc = function(nums) {
  n = nums$Naa + nums$Nao + nums$Nbb + nums$Nbo + nums$Nab + nums$Noo
  return(list(
    pa = (2 * nums$Naa + nums$Nao + nums$Nab) / (2 * n),
    pb = (2 * nums$Nbb + nums$Nbo + nums$Nab) / (2 * n),
    po = (2 * nums$Noo + nums$Nao + nums$Nbo) / (2 * n)
  ))
}

# Implementing the EM algorithm
blood.EM = function(data, start, maxiter = 1000, tol = 1e-10) {
  # Calculate the starting points
  cond.expect = e.calc(X = data, params = start)
  old.params = start
  path = c(iter = 0, pa = start$pa, pb = start$pb, po = start$po)
  
  i = 0
  diff.pa = diff.pb = diff.po = Inf
  while (i < maxiter && diff.pa > tol && diff.pb > tol && diff.po > tol) {
    i = i + 1
    new.params = m.calc(cond.expect)
    
    # Convergence check
    diff.pa = abs(old.params$pa - new.params$pa)
    diff.pb = abs(old.params$pb - new.params$pb)
    diff.pa = abs(old.params$po - new.params$po)
    
    cond.expect = e.calc(X = cond.expect, params = new.params)
    path = rbind(path, 
                 c(iter = i, pa = new.params$pa, pb = new.params$pb, po = new.params$po)
    )
    old.params = new.params
  }
  return(path)
}

# confirmed to work
# obs = list(Na = 26, Nb = 27, Noo = 42, Nab = 7)
# init.params = list(pa = 1/3, pb = 1/3, po = 1/3)
# 
# allele.est = blood.EM(data = obs, start = init.params)
```

<a href="#toc">Back to top</a>

<h3 href="kmeans">K-Means</a>

This can be viewed as a generalization to the mixed model with just two Gaussians. Each cluster represents a multivariate Gaussian and there is a corresponding probability of being in that Gaussian. Recall that the observed likelihood of the two Gaussian mix was: 

$$L_{obs}(x) = \prod^n_{i=1}(1 - p)f(x_i, \mu_1, \sigma_1) + p f(x_i, \mu_2, \sigma_2)$$
Expanding this to account for $k$ Gaussians corresponds to:

For just one observation, the density is:
$$f(x) = \sum^k_{i=1}p_i N(x_i|\mu_i, \Sigma_i)$$

$$L_{obs}(X; \theta) = \prod^n_{i=1} \sum^k_{j=1} p_j N(x_i|\mu_j, \Sigma_j)$$

$$l_{obs}(X; \theta) = \sum^n_{i=1} log \bigg( \sum^k_{j=1} p_j N(x_i|\mu_j, \Sigma_j) \bigg)$$

The $\theta$ is the collection of all the means and variance-covariance matrices and the probabilities of being in the $k^{th}$ cluster needs to be estimated. 



